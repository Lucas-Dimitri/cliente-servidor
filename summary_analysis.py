#!/usr/bin/env python3
# AnÃ¡lise Textual dos Resultados - Cliente-Servidor Python vs Go
import pandas as pd
import numpy as np


def analyze_performance():
    """
    Gera anÃ¡lise textual detalhada dos resultados de performance
    """
    print("=" * 70)
    print("     ANÃLISE DE PERFORMANCE: PYTHON vs GO")
    print("=" * 70)

    # Carregar dados
    try:
        df_py = pd.read_csv("requests_python.csv")
        df_go = pd.read_csv("requests_go.csv")
    except FileNotFoundError as e:
        print(f"âŒ Erro: Arquivo nÃ£o encontrado: {e.filename}")
        return

    # Preparar dados
    df_py["implementation"] = "Python"
    df_go["implementation"] = "Go"
    df_combined = pd.concat([df_py, df_go], ignore_index=True)

    # Limpeza de dados
    df_combined["response_time"] = pd.to_numeric(
        df_combined["response_time"], errors="coerce"
    )
    df_combined.dropna(subset=["response_time"], inplace=True)

    # Remover outliers (Z-score > 3)
    grouped = df_combined.groupby(
        ["num_servers", "num_clients", "num_messages", "implementation"]
    )
    df_combined["z_score"] = grouped["response_time"].transform(
        lambda x: np.abs((x - x.mean()) / x.std()) if x.std() > 0 else 0
    )
    df_cleaned = df_combined[df_combined["z_score"] <= 3]

    print(f"ğŸ“Š Dados carregados:")
    print(f"   â€¢ Python: {len(df_py):,} requisiÃ§Ãµes")
    print(f"   â€¢ Go: {len(df_go):,} requisiÃ§Ãµes")
    print(f"   â€¢ Total apÃ³s limpeza: {len(df_cleaned):,} requisiÃ§Ãµes")
    print(f"   â€¢ Outliers removidos: {len(df_combined) - len(df_cleaned):,}")

    # EstatÃ­sticas gerais
    print("\n" + "=" * 70)
    print("1. ESTATÃSTICAS GERAIS")
    print("=" * 70)

    stats_general = (
        df_cleaned.groupby("implementation")["response_time"]
        .agg(["count", "mean", "median", "std", "min", "max"])
        .round(6)
    )

    print("\nğŸ“ˆ Resumo Geral:")
    for impl in ["Python", "Go"]:
        data = stats_general.loc[impl]
        print(f"\n{impl}:")
        print(f"   â€¢ RequisiÃ§Ãµes: {data['count']:,}")
        print(f"   â€¢ Tempo mÃ©dio: {data['mean']:.4f}s")
        print(f"   â€¢ Mediana: {data['median']:.4f}s")
        print(f"   â€¢ Desvio padrÃ£o: {data['std']:.4f}s")
        print(f"   â€¢ MÃ­nimo: {data['min']:.4f}s")
        print(f"   â€¢ MÃ¡ximo: {data['max']:.4f}s")

    # ComparaÃ§Ã£o direta
    py_mean = stats_general.loc["Python", "mean"]
    go_mean = stats_general.loc["Go", "mean"]
    difference = py_mean - go_mean
    percent_diff = (difference / py_mean) * 100

    print(f"\nğŸ¯ ComparaÃ§Ã£o Direta:")
    print(f"   â€¢ DiferenÃ§a absoluta: {difference:.4f}s")
    print(f"   â€¢ DiferenÃ§a percentual: {percent_diff:.2f}%")
    if go_mean < py_mean:
        print(f"   â€¢ âœ… Go Ã© {abs(percent_diff):.2f}% mais rÃ¡pido que Python")
    else:
        print(f"   â€¢ âœ… Python Ã© {abs(percent_diff):.2f}% mais rÃ¡pido que Go")

    # AnÃ¡lise por cenÃ¡rios
    print("\n" + "=" * 70)
    print("2. ANÃLISE POR CENÃRIOS")
    print("=" * 70)

    scenarios = (
        df_cleaned.groupby(
            ["num_servers", "num_clients", "num_messages", "implementation"]
        )["response_time"]
        .agg(["mean", "std", "count"])
        .reset_index()
    )

    # Melhor performance por cenÃ¡rio
    best_scenarios = []

    for (servers, clients, messages), group in scenarios.groupby(
        ["num_servers", "num_clients", "num_messages"]
    ):
        if len(group) == 2:  # Ambas implementaÃ§Ãµes presentes
            py_time = group[group["implementation"] == "Python"]["mean"].iloc[0]
            go_time = group[group["implementation"] == "Go"]["mean"].iloc[0]

            winner = "Go" if go_time < py_time else "Python"
            improvement = abs(py_time - go_time) / max(py_time, go_time) * 100

            best_scenarios.append(
                {
                    "servers": servers,
                    "clients": clients,
                    "messages": messages,
                    "python_time": py_time,
                    "go_time": go_time,
                    "winner": winner,
                    "improvement": improvement,
                }
            )

    best_df = pd.DataFrame(best_scenarios)

    print(f"\nğŸ“‹ AnÃ¡lise de {len(best_df)} cenÃ¡rios completos:")

    # EstatÃ­sticas dos vencedores
    go_wins = len(best_df[best_df["winner"] == "Go"])
    py_wins = len(best_df[best_df["winner"] == "Python"])

    print(f"\nğŸ† Vencedores por cenÃ¡rio:")
    print(f"   â€¢ Go venceu: {go_wins} cenÃ¡rios ({go_wins/len(best_df)*100:.1f}%)")
    print(f"   â€¢ Python venceu: {py_wins} cenÃ¡rios ({py_wins/len(best_df)*100:.1f}%)")

    # Top 5 maiores melhorias
    print(f"\nğŸš€ Top 5 maiores diferenÃ§as de performance:")
    top_improvements = best_df.nlargest(5, "improvement")

    for i, row in top_improvements.iterrows():
        print(f"   {row['winner']} foi {row['improvement']:.1f}% melhor")
        print(
            f"     CenÃ¡rio: {int(row['servers'])} serv, {int(row['clients'])} cli, {int(row['messages'])} msg"
        )
        print(f"     Python: {row['python_time']:.4f}s vs Go: {row['go_time']:.4f}s")
        print()

    # AnÃ¡lise por nÃºmero de mensagens
    print("\n" + "=" * 70)
    print("3. ANÃLISE POR NÃšMERO DE MENSAGENS")
    print("=" * 70)

    msg_analysis = (
        df_cleaned.groupby(["num_messages", "implementation"])["response_time"]
        .mean()
        .unstack()
    )

    print("\nğŸ“¨ Performance mÃ©dia por nÃºmero de mensagens:")
    for messages in sorted(df_cleaned["num_messages"].unique()):
        py_time = msg_analysis.loc[messages, "Python"]
        go_time = msg_analysis.loc[messages, "Go"]

        print(f"\n{int(messages)} mensagem(s):")
        print(f"   â€¢ Python: {py_time:.4f}s")
        print(f"   â€¢ Go: {go_time:.4f}s")

        if go_time < py_time:
            improvement = (py_time - go_time) / py_time * 100
            print(f"   â€¢ âœ… Go Ã© {improvement:.1f}% mais rÃ¡pido")
        else:
            improvement = (go_time - py_time) / go_time * 100
            print(f"   â€¢ âœ… Python Ã© {improvement:.1f}% mais rÃ¡pido")

    # AnÃ¡lise de escalabilidade
    print("\n" + "=" * 70)
    print("4. ANÃLISE DE ESCALABILIDADE")
    print("=" * 70)

    # Performance vs nÃºmero de clientes
    client_scale = (
        df_cleaned.groupby(["num_clients", "implementation"])["response_time"]
        .mean()
        .unstack()
    )

    print("\nğŸ‘¥ Escalabilidade por nÃºmero de clientes:")
    print(
        f"{'Clientes':<10} {'Python (s)':<12} {'Go (s)':<10} {'Vencedor':<10} {'Melhoria (%)'}"
    )
    print("-" * 60)

    for clients in sorted(df_cleaned["num_clients"].unique()):
        py_time = client_scale.loc[clients, "Python"]
        go_time = client_scale.loc[clients, "Go"]

        if go_time < py_time:
            winner = "Go"
            improvement = (py_time - go_time) / py_time * 100
        else:
            winner = "Python"
            improvement = (go_time - py_time) / go_time * 100

        print(
            f"{int(clients):<10} {py_time:<12.4f} {go_time:<10.4f} {winner:<10} {improvement:.1f}"
        )

    # Performance vs nÃºmero de servidores
    server_scale = (
        df_cleaned.groupby(["num_servers", "implementation"])["response_time"]
        .mean()
        .unstack()
    )

    print("\nğŸ–¥ï¸  Escalabilidade por nÃºmero de servidores:")
    print(
        f"{'Servidores':<12} {'Python (s)':<12} {'Go (s)':<10} {'Vencedor':<10} {'Melhoria (%)'}"
    )
    print("-" * 62)

    for servers in sorted(df_cleaned["num_servers"].unique()):
        py_time = server_scale.loc[servers, "Python"]
        go_time = server_scale.loc[servers, "Go"]

        if go_time < py_time:
            winner = "Go"
            improvement = (py_time - go_time) / py_time * 100
        else:
            winner = "Python"
            improvement = (go_time - py_time) / go_time * 100

        print(
            f"{int(servers):<12} {py_time:<12.4f} {go_time:<10.4f} {winner:<10} {improvement:.1f}"
        )

    # ConclusÃµes
    print("\n" + "=" * 70)
    print("5. CONCLUSÃ•ES E RECOMENDAÃ‡Ã•ES")
    print("=" * 70)

    overall_go_wins = go_wins / len(best_df) * 100

    print(f"\nğŸ¯ Resumo Executivo:")

    if overall_go_wins > 50:
        print(
            f"   â€¢ âœ… Go demonstrou superioridade em {overall_go_wins:.1f}% dos cenÃ¡rios"
        )
        print(f"   â€¢ ğŸš€ Go Ã© em mÃ©dia {abs(percent_diff):.2f}% mais rÃ¡pido que Python")
        print(f"   â€¢ ğŸ“ˆ Go mostra melhor escalabilidade em cargas altas")

        print(f"\nğŸ’¡ RecomendaÃ§Ãµes:")
        print(f"   â€¢ Priorizar Go para sistemas de alta performance")
        print(f"   â€¢ Go Ã© ideal para microserviÃ§os e APIs de baixa latÃªncia")
        print(f"   â€¢ Considerar migraÃ§Ã£o gradual de componentes crÃ­ticos")
    else:
        print(
            f"   â€¢ âœ… Python demonstrou competitividade em {100-overall_go_wins:.1f}% dos cenÃ¡rios"
        )
        print(
            f"   â€¢ ğŸ¤ DiferenÃ§a mÃ©dia de apenas {abs(percent_diff):.2f}% entre as implementaÃ§Ãµes"
        )
        print(f"   â€¢ ğŸ“ˆ Ambas linguagens mostram boa escalabilidade")

        print(f"\nğŸ’¡ RecomendaÃ§Ãµes:")
        print(f"   â€¢ Python mantÃ©m-se viÃ¡vel para a maioria dos casos")
        print(f"   â€¢ Foco na otimizaÃ§Ã£o antes de considerar mudanÃ§a de linguagem")
        print(f"   â€¢ Go pode ser considerado para componentes especÃ­ficos")

    print(f"\nğŸ“Š Arquivos de visualizaÃ§Ã£o gerados:")
    print(f"   â€¢ analysis_results_interactive/ (12 grÃ¡ficos 3D interativos)")
    print(f"   â€¢ Abra qualquer .html no navegador para visualizaÃ§Ã£o detalhada")

    print("\n" + "=" * 70)
    print("     ANÃLISE CONCLUÃDA")
    print("=" * 70)


if __name__ == "__main__":
    analyze_performance()
