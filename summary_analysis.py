#!/usr/bin/env python3
# AnÃ¡lise Textual dos Resultados - Cliente-Servidor Python vs Go
import pandas as pd
import numpy as np
from datetime import datetime


def analyze_performance():
    """
    Gera anÃ¡lise textual detalhada dos resultados de performance e salva em arquivo Markdown
    """
    # Configurar arquivo de saÃ­da
    output_file = "performance_analysis_report.md"

    # Criar buffer para capturar toda a saÃ­da
    output_lines = []

    def write_output(text):
        """FunÃ§Ã£o auxiliar para escrever tanto no terminal quanto no buffer"""
        print(text)
        output_lines.append(text)

    # CabeÃ§alho do relatÃ³rio
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    write_output("# ğŸ“Š AnÃ¡lise de Performance: Python vs Go")
    write_output("")
    write_output(f"**RelatÃ³rio gerado em:** {timestamp}")
    write_output("")
    write_output("## ğŸ¯ Metodologia")
    write_output("")
    write_output(
        "Este relatÃ³rio analisa o **tempo total para processar todos os clientes** de cada cenÃ¡rio,"
    )
    write_output("nÃ£o apenas o tempo mÃ©dio individual. A fÃ³rmula utilizada Ã©:")
    write_output("")
    write_output(
        "**Tempo Total do CenÃ¡rio = Tempo MÃ©dio por Cliente Ã— NÃºmero de Clientes**"
    )
    write_output("")
    write_output(
        "Esta abordagem fornece uma visÃ£o mais realista do desempenho total do sistema."
    )
    write_output("")
    write_output("---")

    # Carregar dados
    try:
        df_py = pd.read_csv("requests_python.csv")
        df_go = pd.read_csv("requests_go.csv")
    except FileNotFoundError as e:
        error_msg = f"âŒ Erro: Arquivo nÃ£o encontrado: {e.filename}"
        write_output(error_msg)
        # Salvar erro no arquivo
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("\n".join(output_lines))
        return

    # Preparar dados
    df_py["implementation"] = "Python"
    df_go["implementation"] = "Go"
    df_combined = pd.concat([df_py, df_go], ignore_index=True)

    # Limpeza de dados
    df_combined["response_time"] = pd.to_numeric(
        df_combined["response_time"], errors="coerce"
    )
    df_combined.dropna(subset=["response_time"], inplace=True)

    # Remover outliers (Z-score > 3)
    grouped = df_combined.groupby(
        ["num_servers", "num_clients", "num_messages", "implementation"]
    )
    df_combined["z_score"] = grouped["response_time"].transform(
        lambda x: np.abs((x - x.mean()) / x.std()) if x.std() > 0 else 0
    )
    df_cleaned = df_combined[df_combined["z_score"] <= 3]

    write_output("## ï¿½ Resumo dos Dados")
    write_output("")
    write_output("| MÃ©trica | Python | Go | Total |")
    write_output("|---------|--------|----|----|")
    write_output(
        f"| RequisiÃ§Ãµes originais | {len(df_py):,} | {len(df_go):,} | {len(df_py) + len(df_go):,} |"
    )
    write_output(
        f"| RequisiÃ§Ãµes apÃ³s limpeza | {len(df_cleaned[df_cleaned['implementation'] == 'Python']):,} | {len(df_cleaned[df_cleaned['implementation'] == 'Go']):,} | {len(df_cleaned):,} |"
    )
    write_output(
        f"| Outliers removidos | - | - | {len(df_combined) - len(df_cleaned):,} |"
    )
    write_output("")

    # EstatÃ­sticas gerais
    write_output("## 1ï¸âƒ£ EstatÃ­sticas Gerais")
    write_output("")

    stats_general = (
        df_cleaned.groupby("implementation")["response_time"]
        .agg(["count", "mean", "median", "std", "min", "max"])
        .round(6)
    )

    write_output("### ï¿½ EstatÃ­sticas Detalhadas")
    write_output("")
    write_output(
        "| ImplementaÃ§Ã£o | RequisiÃ§Ãµes | Tempo MÃ©dio (s) | Mediana (s) | Desvio PadrÃ£o (s) | MÃ­nimo (s) | MÃ¡ximo (s) |"
    )
    write_output(
        "|---------------|-------------|-----------------|-------------|------------------|------------|------------|"
    )

    for impl in ["Python", "Go"]:
        data = stats_general.loc[impl]
        write_output(
            f"| **{impl}** | {data['count']:,.0f} | {data['mean']:.4f} | {data['median']:.4f} | {data['std']:.4f} | {data['min']:.4f} | {data['max']:.4f} |"
        )

    write_output("")

    # ComparaÃ§Ã£o direta
    py_mean = stats_general.loc["Python", "mean"]
    go_mean = stats_general.loc["Go", "mean"]
    difference = py_mean - go_mean
    # DiferenÃ§a percentual sempre em relaÃ§Ã£o ao mais lento
    if abs(go_mean) > abs(py_mean):
        percent_diff = (abs(difference) / abs(go_mean)) * 100
    else:
        percent_diff = (abs(difference) / abs(py_mean)) * 100

    write_output("### ğŸ¯ ComparaÃ§Ã£o Direta")
    write_output("")
    write_output("| MÃ©trica | Valor |")
    write_output("|---------|-------|")
    write_output(f"| DiferenÃ§a absoluta | **{difference:.4f}s** |")
    write_output(f"| DiferenÃ§a percentual | **{percent_diff:.2f}%** |")

    if py_mean < go_mean:
        write_output(
            f"| **Resultado** | âœ… **Python Ã© {percent_diff:.2f}% mais rÃ¡pido que Go** |"
        )
    elif go_mean < py_mean:
        write_output(
            f"| **Resultado** | âœ… **Go Ã© {percent_diff:.2f}% mais rÃ¡pido que Python** |"
        )
    else:
        write_output(f"| **Resultado** | âš–ï¸ **Empate tÃ©cnico** |")

    write_output("")

    # AnÃ¡lise por cenÃ¡rios
    write_output("## 2ï¸âƒ£ AnÃ¡lise por CenÃ¡rios")
    write_output("")

    scenarios = (
        df_cleaned.groupby(
            ["num_servers", "num_clients", "num_messages", "implementation"]
        )["response_time"]
        .agg(["mean", "std", "count"])
        .reset_index()
    )

    # Melhor performance por cenÃ¡rio
    best_scenarios = []

    for (servers, clients, messages), group in scenarios.groupby(
        ["num_servers", "num_clients", "num_messages"]
    ):
        if len(group) == 2:  # Ambas implementaÃ§Ãµes presentes
            py_time_avg = group[group["implementation"] == "Python"]["mean"].iloc[0]
            go_time_avg = group[group["implementation"] == "Go"]["mean"].iloc[0]

            # Calcular tempo total do cenÃ¡rio (tempo mÃ©dio Ã— nÃºmero de clientes)
            py_time_total = py_time_avg * clients
            go_time_total = go_time_avg * clients

            winner = "Go" if go_time_total < py_time_total else "Python"
            improvement = (
                abs(py_time_total - go_time_total)
                / max(py_time_total, go_time_total)
                * 100
            )

            best_scenarios.append(
                {
                    "servers": servers,
                    "clients": clients,
                    "messages": messages,
                    "python_time": py_time_total,
                    "go_time": go_time_total,
                    "winner": winner,
                    "improvement": improvement,
                }
            )

    best_df = pd.DataFrame(best_scenarios)

    write_output(f"**Total de cenÃ¡rios analisados:** {len(best_df)}")
    write_output("")

    # EstatÃ­sticas dos vencedores
    go_wins = len(best_df[best_df["winner"] == "Go"])
    py_wins = len(best_df[best_df["winner"] == "Python"])

    write_output("### ğŸ† Vencedores por CenÃ¡rio")
    write_output("")
    write_output("| ImplementaÃ§Ã£o | CenÃ¡rios Vencidos | Percentual |")
    write_output("|---------------|-------------------|------------|")
    write_output(f"| **Go** | {go_wins} | **{go_wins/len(best_df)*100:.1f}%** |")
    write_output(f"| **Python** | {py_wins} | **{py_wins/len(best_df)*100:.1f}%** |")
    write_output("")

    # Top 5 maiores melhorias
    top_improvements = best_df.nlargest(5, "improvement")

    write_output("### ğŸš€ Top 5 Maiores DiferenÃ§as de Tempo Total")
    write_output("")
    write_output(
        "| Ranking | Vencedor | Melhoria | CenÃ¡rio | Python Total (s) | Go Total (s) |"
    )
    write_output(
        "|---------|----------|----------|---------|------------------|--------------|"
    )

    for idx, (i, row) in enumerate(top_improvements.iterrows(), 1):
        scenario = f"{int(row['servers'])} serv, {int(row['clients'])} cli, {int(row['messages'])} msg"
        write_output(
            f"| {idx} | **{row['winner']}** | **{row['improvement']:.1f}%** | {scenario} | {row['python_time']:.2f} | {row['go_time']:.2f} |"
        )

    write_output("")

    # AnÃ¡lise por nÃºmero de mensagens
    write_output("## 3ï¸âƒ£ AnÃ¡lise por NÃºmero de Mensagens")
    write_output("")

    msg_analysis = (
        df_cleaned.groupby(["num_messages", "implementation"])["response_time"]
        .mean()
        .unstack()
    )

    write_output("### ğŸ“¨ Performance MÃ©dia por NÃºmero de Mensagens")
    write_output("")
    write_output("| Mensagens | Python (s) | Go (s) | Vencedor | Melhoria |")
    write_output("|-----------|------------|--------|----------|----------|")

    for messages in sorted(df_cleaned["num_messages"].unique()):
        py_time = msg_analysis.loc[messages, "Python"]
        go_time = msg_analysis.loc[messages, "Go"]

        if py_time < go_time:
            improvement = (go_time - py_time) / go_time * 100
            winner = f"âœ… **Python**"
            improvement_text = f"{improvement:.1f}% mais rÃ¡pido"
        elif go_time < py_time:
            improvement = (py_time - go_time) / py_time * 100
            winner = f"âœ… **Go**"
            improvement_text = f"{improvement:.1f}% mais rÃ¡pido"
        else:
            winner = f"âš–ï¸ Empate"
            improvement_text = "0.0%"

        write_output(
            f"| {int(messages):,} | {py_time:.4f} | {go_time:.4f} | {winner} | {improvement_text} |"
        )

    write_output("")

    # AnÃ¡lise de escalabilidade
    write_output("## 4ï¸âƒ£ AnÃ¡lise de Escalabilidade")
    write_output("")

    # Performance vs nÃºmero de clientes
    client_scale = (
        df_cleaned.groupby(["num_clients", "implementation"])["response_time"]
        .mean()
        .unstack()
    )

    write_output("### ğŸ‘¥ Escalabilidade por NÃºmero de Clientes")
    write_output("")
    write_output("| Clientes | Python (s) | Go (s) | Vencedor | Melhoria (%) |")
    write_output("|----------|------------|--------|----------|--------------|")

    for clients in sorted(df_cleaned["num_clients"].unique()):
        py_time = client_scale.loc[clients, "Python"]
        go_time = client_scale.loc[clients, "Go"]

        if py_time < go_time:
            winner = "**Python**"
            improvement = (go_time - py_time) / go_time * 100
        elif go_time < py_time:
            winner = "**Go**"
            improvement = (py_time - go_time) / py_time * 100
        else:
            winner = "âš–ï¸ Empate"
            improvement = 0.0

        write_output(
            f"| {int(clients)} | {py_time:.4f} | {go_time:.4f} | {winner} | {improvement:.1f} |"
        )

    write_output("")

    # Performance vs nÃºmero de servidores
    server_scale = (
        df_cleaned.groupby(["num_servers", "implementation"])["response_time"]
        .mean()
        .unstack()
    )

    write_output("### ğŸ–¥ï¸ Escalabilidade por NÃºmero de Servidores")
    write_output("")
    write_output("| Servidores | Python (s) | Go (s) | Vencedor | Melhoria (%) |")
    write_output("|------------|------------|--------|----------|--------------|")

    for servers in sorted(df_cleaned["num_servers"].unique()):
        py_time = server_scale.loc[servers, "Python"]
        go_time = server_scale.loc[servers, "Go"]

        if py_time < go_time:
            winner = "**Python**"
            improvement = (go_time - py_time) / go_time * 100
        elif go_time < py_time:
            winner = "**Go**"
            improvement = (py_time - go_time) / py_time * 100
        else:
            winner = "âš–ï¸ Empate"
            improvement = 0.0

        write_output(
            f"| {int(servers)} | {py_time:.4f} | {go_time:.4f} | {winner} | {improvement:.1f} |"
        )

    write_output("")

    # ConclusÃµes
    write_output("## 5ï¸âƒ£ ConclusÃµes e RecomendaÃ§Ãµes")
    write_output("")

    overall_go_wins = go_wins / len(best_df) * 100
    overall_py_wins = py_wins / len(best_df) * 100

    write_output("### ğŸ¯ Resumo Executivo")
    write_output("")

    if overall_py_wins > 50:
        write_output(
            f"- âœ… **Python demonstrou superioridade em {overall_py_wins:.1f}% dos cenÃ¡rios**"
        )
        write_output(
            f"- ğŸš€ **Python Ã© em mÃ©dia {abs(percent_diff):.2f}% mais rÃ¡pido que Go**"
        )
        write_output(f"- ğŸ“ˆ **Python mostra melhor escalabilidade em cargas altas**")
        write_output("")

        write_output("### ğŸ’¡ RecomendaÃ§Ãµes")
        write_output("")
        write_output("- â­ **Priorizar Python para sistemas de alta performance**")
        write_output(
            "- ğŸ”¥ **Python Ã© ideal para microserviÃ§os e APIs de baixa latÃªncia**"
        )
        write_output(
            "- ğŸ”„ **Considerar migraÃ§Ã£o gradual de componentes crÃ­ticos para Python**"
        )
    elif overall_go_wins > 50:
        write_output(
            f"- âœ… **Go demonstrou superioridade em {overall_go_wins:.1f}% dos cenÃ¡rios**"
        )
        write_output(
            f"- ğŸš€ **Go Ã© em mÃ©dia {abs(percent_diff):.2f}% mais rÃ¡pido que Python**"
        )
        write_output(f"- ğŸ“ˆ **Go mostra melhor escalabilidade em cargas altas**")
        write_output("")

        write_output("### ğŸ’¡ RecomendaÃ§Ãµes")
        write_output("")
        write_output("- â­ **Priorizar Go para sistemas de alta performance**")
        write_output("- ğŸ”¥ **Go Ã© ideal para microserviÃ§os e APIs de baixa latÃªncia**")
        write_output(
            "- ğŸ”„ **Considerar migraÃ§Ã£o gradual de componentes crÃ­ticos para Go**"
        )
    else:
        write_output(
            f"- âš–ï¸ **Empate tÃ©cnico: ambas as linguagens apresentam desempenho semelhante**"
        )
        write_output(f"- ğŸ“ˆ **Ambas linguagens mostram boa escalabilidade**")
        write_output("")

        write_output("### ğŸ’¡ RecomendaÃ§Ãµes")
        write_output("")
        write_output(
            "- âœ… **Ambas as linguagens sÃ£o viÃ¡veis para a maioria dos casos**"
        )
        write_output(
            "- ğŸ”§ **Foco na otimizaÃ§Ã£o antes de considerar mudanÃ§a de linguagem**"
        )
        write_output(
            "- ğŸ¯ **Escolha pode ser baseada em outros critÃ©rios (equipe, ecossistema, etc.)**"
        )

    write_output("")

    write_output("## ï¿½ Arquivos Gerados")
    write_output("")
    write_output("| Arquivo | DescriÃ§Ã£o |")
    write_output("|---------|-----------|")
    write_output(f"| `{output_file}` | Este relatÃ³rio completo em Markdown |")
    write_output(
        "| `analysis_results_interactive/` | GrÃ¡ficos 3D de tempo total por cenÃ¡rio |"
    )
    write_output("| `requests_python.csv` | Dados brutos Python |")
    write_output("| `requests_go.csv` | Dados brutos Go |")
    write_output("")
    write_output(
        "ğŸ’¡ **Dica:** Abra qualquer arquivo `.html` da pasta `analysis_results_interactive/` no navegador para visualizaÃ§Ã£o detalhada!"
    )
    write_output("")

    write_output("---")
    write_output("**AnÃ¡lise ConcluÃ­da** âœ…")
    write_output("")

    # Salvar relatÃ³rio em arquivo
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("\n".join(output_lines))
        print(f"\nğŸ’¾ RelatÃ³rio salvo em: {output_file}")
        print(f"ğŸ“„ Total de linhas: {len(output_lines)}")
        print(f"ğŸ“‚ Arquivo criado com sucesso!")
    except Exception as e:
        print(f"âŒ Erro ao salvar arquivo: {e}")
        return

    return output_file


if __name__ == "__main__":
    report_file = analyze_performance()
    if report_file:
        print(f"\nğŸ‰ AnÃ¡lise concluÃ­da! RelatÃ³rio disponÃ­vel em: {report_file}")
